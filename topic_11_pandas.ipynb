{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13401784",
   "metadata": {},
   "source": [
    "# Topic 11: Pandas\n",
    "\n",
    "We are starting a new module, _Analytics_.  Our first stop will be to explore some of the capabilities of the _Pandas_ package, which provides efficient storage and manipulations of vectors and arrays of data.  As we look to perform analytics on data, in many cases we use Pandas to hold that data.\n",
    "\n",
    "Feel free to download this lecture from Canvas.  This is a Jupyter Notebook, an ipynb file. Place this in one of your project directories.  In addition, there is a related zip file containing a few data files.  Download the zip as well, and extract the files into that same project directory.  Then activate that directory's environment and run Jupyter Notebook from there.  You can then run these examples live.  Feel free to experiment, either changing some of the cells, then rerunning them to see the changes, or by creating new cells and experimenting there.  One of the best ways to learn is by doing (I've heard that somewhere), so take some time and experiment.\n",
    "\n",
    "## Importing Packages\n",
    "\n",
    "When we create a new Jupyter notebook, one of the first things we would do is import the packages that we will be using.  In addition to importing Pandas, we frequently also import _numpy_ and _matplotlib_.  This lecture mostly focuses on Pandas, but we will touch briefly on these others.  Typically we would import the packages in the first cell of the notebook, as shown here:  (Be sure to run the cell, so that the imports will actually happen!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9585de",
   "metadata": {},
   "source": [
    "When that cell is run, the notebook does not generate any output, but the packages are loaded and available to use.\n",
    "\n",
    "Note that the import of pandas also gave a new name, 'pd', for the package.  This is for our convenience, so we can use the abbreviation in our code.  Instead of saying 'pandas.Series(...)' we can say 'pd.Series(...)', and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb04f6",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "Pandas contains two basic data structures which we will use a lot.  The first, which is the simplest, but not that frequently used, is a vector, which Pandas calls a 'Series'.\n",
    "\n",
    "We could use a Python array, but Python arrays are not very efficient.  They take more memory, using them is slower, and Python does not provide many of the useful methods that Pandas provides.  For this reason, we will prefer to use a Series.\n",
    "\n",
    "However, one of the ways to construct a Series is to first build an array of data in Python, then pass this to Pandas.  Pandas will convert the array to a Series, and from then on things run better.  Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a19288",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [4, 8, 15, 16, 23, 42]\n",
    "\n",
    "vec = pd.Series(data)\n",
    "\n",
    "vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2d614",
   "metadata": {},
   "source": [
    "* In the first line, we construct a Python array.\n",
    "\n",
    "* In the second line, we ask Pandas to create a Series from this array.\n",
    "\n",
    "* In the third line, we ask Python to _print out_ this Series.  When you run the cell, it will list the contents of _vec_ just below the cell.\n",
    "\n",
    "We could have also combined the first two lines, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pd.Series([4, 8, 15, 16, 23, 42])\n",
    "\n",
    "vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ede29",
   "metadata": {},
   "source": [
    "For this simple example, we build an array in Python, then used this to initialize the Series.  In a more realistic example, we would either have programmatically built the vector, or we would have loaded the data from an external file.  We will see examples of this in a few minutes.\n",
    "\n",
    "Just a few notes about the output of that Series:\n",
    "\n",
    "* Each line displays one cell of the Series (one entry in the vector).  The line first displays the index, then it displays the value in the cell.\n",
    "\n",
    "* At the end, Pandas prints the datatype of the values, if all of the cells have the same type of data.  In this case, these are all 64-bit integer values.\n",
    "\n",
    "* If the values are strings, or if the types are objects, arrays, or have mixed type, the datatype listed is 'object'\n",
    "\n",
    "The following examples show these details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6057957",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1.2, 3.7, 7.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2273cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([True, False, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca16a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(['one', 'two', 'three'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc64c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([4, 5, 'six', 5 < 8, [2, 3], 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1de1f",
   "metadata": {},
   "source": [
    "## Pandas DataFrame\n",
    "The second basic data structure in Pandas, the one used most often, is _DataFrame_, which represents a tabular arrangement of data, with rows and columns.  You can think of this as a mini-EXCEL spreadsheet, or as a database table.\n",
    "\n",
    "Each column has a name, and all of the _cells_ below it form a Series.\n",
    "\n",
    "Each row has an index, and represents one _entry_ in the table.\n",
    "\n",
    "The first row has an index of 0.  In each of the columns, the cell at index 0 gives the corresponding value for this entry.\n",
    "\n",
    "Enough talking, let's see an example.  In the following cell, we define a Python object, which is a set of key/value pairs.  Each of the keys are in fact the name of a column, and the associated value is an array containing the data to be placed in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38490e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Burger': [ 'Big Mac', 'Whopper', 'Double Double', 'The Big Carl', \n",
    "            'Charburger', 'Red\\'s Tavern Double', 'Double Del Cheeseburger'],\n",
    "    'Cost': [3.99, 4.19, 3.45, 5.19, 3.45, 6.99, 6.39],\n",
    "    'Calories': [563, 677, 670, 920, 470, 650, 720]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32bad68",
   "metadata": {},
   "source": [
    "We can turn this inefficient Python 'table' into an efficient Pandas DataFrame as follows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43893ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e73795",
   "metadata": {},
   "source": [
    "Now that we have a DataFrame, we can print out the contents by simply listing the Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a619803",
   "metadata": {},
   "source": [
    "In this case we are taking all of the columns.  But in other examples, we might have a large data object, but we only want to use portions of it in our code.  So we list the columns of interest.  Pandas will then only take the columns that we indicated.  Notice, by the way, that we can rearrange the columns, and even duplicate the columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers2 = pd.DataFrame(data, columns = ['Cost', 'Burger', 'Calories', 'Cost'])\n",
    "\n",
    "burgers2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13738890",
   "metadata": {},
   "source": [
    "In this example, the table was small, so the whole table was printed.  If the table had many lines, the output would have listed the header of the table, the first few lines, then a line of ellipses (...), then the last few lines.\n",
    "\n",
    "Entering data using the Python object/arrays is very inefficient.  If we were algorithmically generating the data, we would write a program to construct the input data.  However, in most cases, we would read the data into the DataFrame from an external file.  Pandas supports reading data in a variety of formats, but one of the easiest and most common is to use a CSV (_comma-separated-value_) file.  In this file, the first row provides the names of all the columns, and each of the remaining rows gives the values for one entry (row) in the DataFrame.  Commas are used to indicate when to switch to the next column.\n",
    "\n",
    "The following line of code shows how to load the data from a CSV file.  If you have loaded the files from the zip file, then the following cell will be able to find the file and extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman = pd.read_csv('spiderman.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1be47",
   "metadata": {},
   "source": [
    "Having loaded the data, we can then print out the contents of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67612098",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b5470",
   "metadata": {},
   "source": [
    "As mentioned when loading from a Python object, we can also select which columns of data to load, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman = pd.read_csv('spiderman.csv',\n",
    "                       usecols = ['Film', 'Actor', 'Release Date', 'Ranking', \n",
    "                                  'Rotten Tomatoes', 'Metacritic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e945e6",
   "metadata": {},
   "source": [
    "We can then print this out and see that only the requested columns appear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df657f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd87f85",
   "metadata": {},
   "source": [
    "## Examining the Data\n",
    "We can get a quick peek at the contents of the table using the _head_ method.  This will print the header of the table, then list the first five rows of data.  We would typically use this so we can verify that the data loaded correctly, or to see what kind of data is in the DataFrame.\n",
    "\n",
    "In the second example that follows, we can pass a number to the _head_ method.  This overrides the default value of '5', so we can, for example, look at the first three rows of data in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ab729",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef9031",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053259f8",
   "metadata": {},
   "source": [
    "There is another method, _tail_, which lists rows at the bottom of the table.  Again, the table header is drawn, but then the last five rows of data are displayed.  You can also pass a number to _tail_ to change the number of rows displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473b5b0",
   "metadata": {},
   "source": [
    "We can ask for just the names of the columns, by accessing the _columns_ attribute.  This contains an _index_ object that has an array of the names, and an indication of the datatype of this array, which will be _object_ (since the entries are strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7eeede",
   "metadata": {},
   "source": [
    "We can also ask for the datatypes for each of the columns, using _dtypes_.  This returns a Series that uses the column names as the indices and the corresponding datatypes as the values.  If a column has mixed types, it lists the type _object_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ab947",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8cf905",
   "metadata": {},
   "source": [
    "Going in the other dimension, we can ask for information about the rows.  While the columns have names, the rows simply have an index.  If we access the _index_ attribute, Pandas will print a description of the indices.  In a typical case, there are many rows, and these are sequentially numbered, so in most cases Pandas does not enumerate all of the values, but rather shows the _formula_ for computing the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d57aaf",
   "metadata": {},
   "source": [
    "The above states that the indices form a single _range_, which starts at 0 and ends _before_ 9, incrementing by 1.  So the indicies run from 0 to 8, inclusive.\n",
    "\n",
    "We can extract a Python array from the DataFrame.  This is not frequently done, but maybe you will be performing computations on this array, and would rather not use the DataFrame object.  Access the _values_ attribute to get the data as an array.\n",
    "\n",
    "The result is actually a 2-dimensional array.  The outer array is the list of rows, and each row is an array of each of the column values for that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a1db1",
   "metadata": {},
   "source": [
    "Another convenient method is _describe_.  This examines all of the columns that contain numeric data, outputing a chart that gives typical summary information for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d20689",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8465c",
   "metadata": {},
   "source": [
    "* The _count_ row gives the number of entries in each column.\n",
    "* The _mean_ row gives the average value for each column.\n",
    "* The _std_ row gives the standard deviation for each column (we will talk about _standard deviation_ in a few lectures).\n",
    "* The _min_ row gives the smallest value in each column.\n",
    "* The _max_ row gives the largest value in each column.\n",
    "* The _25%_, _50%_, and _75%_ values list the column entries such that 25% (or 50%, or 75%) of all the entries have that value or less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903bf33",
   "metadata": {},
   "source": [
    "## Modifying the Data\n",
    "One change that can be made to the data is to change the names of the columns.  Perhaps some of the column names are fairly long, or maybe not descriptive.  Maybe you just want to change the name.  Recall that these column names may have come from the CSV file, or other external representation, so up to this point the names are out of your control.\n",
    "\n",
    "However, recall that the _DataFrame_ has a _columns_ attribute, which gives the names of the columns.  You can rename the columns by assigning a new array of strings to the _columns_ attributes!  Note that the size of this array must match the number of columns in the _DataFrame_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.columns= ['Film', 'Date', 'Actor', 'Rank', 'Tomatoes', 'Critic']\n",
    "\n",
    "spiderman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4cd92",
   "metadata": {},
   "source": [
    "If we _index_ into the _DataFrame_, passing the name of one of the columns, the return value is a _Series_ that contains the values of that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman['Film']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826de22e",
   "metadata": {},
   "source": [
    "If we _index_ into the _DataFrame_ by giving two index values, separated by a colon (the typical Python method to declare a range of values), the return is a new _DataFrame_ containing only the selected rows.  There are a couple of notes:\n",
    "* The first number gives the first index, inclusive.\n",
    "* The second number gives the final index, exclusive.\n",
    "* Note that the index values for this new _DataFrame_ match the index values from the original _DataFrame_, so they don't necessarily start with 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman[3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af1130",
   "metadata": {},
   "source": [
    "## Digression\n",
    "To illustrate the next couple of points, we will move from our Spiderman _DataFrame_, but we will return soon!\n",
    "\n",
    "For some use cases, you might need an array of randomly generated values.  Let's build such an array!\n",
    "\n",
    "The core routine we will use is a method in _numpy_ which builds a 2-dimensional array of random values (you can also build 1-dimensional arrays or 3-dimensional arrays, but that would be a digression of our digression...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f95836",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dcc58",
   "metadata": {},
   "source": [
    "That works fine to get the data for the _DataFrame_.  But maybe we want to provide interesting column names.\n",
    "We could simply provide an array of names.  However, since this is just random data, and we don't have any more descriptive names for the columns, we can just label the columns 'A', 'B', ...\n",
    "* We could give the column names like this: ['A', 'B', 'C', 'D', 'E']\n",
    "* Alternatively, we can use the String _list_ method: list('ABCDE').  That list method makes an array where each entry in the array is a single-character string taken from the input parameter.\n",
    "* If we don't give any column names, Pandas will just name the first column '1', the second column '2', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list('ABCDE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade9bd2",
   "metadata": {},
   "source": [
    "We can also give interesting row 'names', which are the indicies.  \n",
    "\n",
    "If we don't give row names, Pandas will simply sequentially number the rows.\n",
    "\n",
    "For this example, let's create row index values as dates.  Pandas has a function, _date_range_, which will compute an array of index values, given a starting date and the number of indicies to generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('2022-9-15', periods=12)\n",
    "\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc8bdf",
   "metadata": {},
   "source": [
    "Putting this all together, the following creates a new _DataFrame_, based on an array of randomly generated values, and given the _date_ indicies (from the previous cell), and the simple column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b39e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = pd.DataFrame(np.random.randn(12, 5), index = dates, columns = list('ABCDE'))\n",
    "\n",
    "rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b803fa1",
   "metadata": {},
   "source": [
    "As shown previously, we can run the _describe()_ method to get an overview of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd.A.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ef220",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd[3:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e8cfd",
   "metadata": {},
   "source": [
    "## Undigression?\n",
    "\n",
    "Back to our Spiderman example.  Previously we showed how to extract a single column from the _DataFrame_, or how to extract a series of rows.  These techniques can be combined to select a _region_ from the _DataFrame_: we list the range of rows, and list the set of columns to keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.loc[3:5, ['Film', 'Actor']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b2510",
   "metadata": {},
   "source": [
    "The annoying thing about this?  Note that for the _loc_ function, the upper number in the range is _included_, while in the previous examples it is _excluded_.  Sigh.\n",
    "\n",
    "We can also get the contents of a single cell by giving one specific index and one specific column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586bd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.loc[3, 'Actor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353bdb6",
   "metadata": {},
   "source": [
    "There are two ways to select a cell, using _loc_ and using _at_, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.at[3, 'Actor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25643e",
   "metadata": {},
   "source": [
    "## Index by Position\n",
    "In the previous examples, we were indicating specific rows by giving the index 'label' of the row, and indicating specific columns by column name.  One subtle thing: If we create a sub-_DataFrame_, it's rows will have the same indicies as the original table.\n",
    "\n",
    "An alternate way to select is using the _iloc_ method, which always indexes by an integer, and this is always the current order in the specific _DataFrame_.  In the following example, we give a single integer value, so this 'selects' the row with that index.  The return value is a _Series_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bd7576",
   "metadata": {},
   "source": [
    "If we give two values, the first index selects which row, and the second index selects which column in that row.  The return value is the specific cell contents.  As usual, the indicies start at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04779998",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.iloc[2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec1987",
   "metadata": {},
   "source": [
    "A range of values can be given, rather than specific numbers.  In this case, a _DataFrame_ will be returned.  Also note that in this instance, the last or upper values specified are _exclusive_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed0452",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.iloc[2:4, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf6b5a",
   "metadata": {},
   "source": [
    "As yet another option, an array of values can be passed for either or both of the dimensions.  In this case, the resulting _DataFrame_ will have the indicated set of rows and the indicated set of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c279125",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.iloc[[1,3,5],[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d640a246",
   "metadata": {},
   "source": [
    "I did a couple of experiments.  In the following, the row and column numbers were not in increasing order.  The output _DataSet_ had the rows and columns in the order I specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.iloc[[1,5,3],[2,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986d6d6",
   "metadata": {},
   "source": [
    "This led, of course, to one more experiment: What if one of the index values was repeated?  Answer: It did what I asked, and duplicated the row of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.iloc[[1,3,1],[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d8357c",
   "metadata": {},
   "source": [
    "## Boolean Indexing\n",
    "\n",
    "Comparisons can be performed upon a _Series_.  This will create a new boolean _Series_, where each value of the output is the result of performing the comparison upon the corresponding value of the input.  Recall that we can get a _Series_ from the _DataFrame_ by indexing with the name of a column.  So, for example, we can get a boolean _Series_ that indicates which rows of the table have Tobey Maguire as the actor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b859f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman['Actor'] == 'Tobey Maguire'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1de89",
   "metadata": {},
   "source": [
    "As a more complex example, we can get a vector indicating where 'Tomatoes' has a score of 90 or higher and where 'Critic' has a score of 80 or higher.  Also note in this example that we can select a column by using the dot notation rather than indexing by the column name!  _Note: for this example, the parentheses are required.  Otherwise Python has trouble parsing the expression._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "(spiderman.Tomatoes >= 90) & (spiderman.Critic >= 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb167a",
   "metadata": {},
   "source": [
    "What is the use of these boolean _Series_?\n",
    "\n",
    "We can use them to index the _DataFrame_.  The result is that we get a new _DataFrame_ which only contains the rows where the expression evaluated to _TRUE_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman[spiderman.Actor == 'Tobey Maguire']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2e3a6",
   "metadata": {},
   "source": [
    "Another little more complex example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa385c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman[(spiderman['Rank'] < 50) & (spiderman['Critic'] > 80)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b7066",
   "metadata": {},
   "source": [
    "## Adding Columns\n",
    "A new column can be added to a _DataFrame_ simply by selecting a new column and providing an array of data.  The array should have the same length as the number of rows in the _DataFrame_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70537ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman['Score'] = [100, 90, 95, 80, 85, 75, 60, 92, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17326b17",
   "metadata": {},
   "source": [
    "A _DataFrame_ can be _transposed_, which switches the rows and columns, using the _T_ 'attribute':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c236b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc1a3c",
   "metadata": {},
   "source": [
    "You can add a new row.  You can change the value of one cell.  But we don't usually do this, usually we are just processing the data we have received."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d5a84",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "Make a Jupyter Notebook of your own, load some data, then explore what you can do.\n",
    "\n",
    "In addition to the Spiderman dataset, in 'spiderman.csv', I've also included a dataset covering some James Bond (007) movies, in the file 'jamesbond.csv'.  Load that data file, then experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b265a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
